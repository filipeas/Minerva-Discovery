{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "\n",
    "from scipy.ndimage import gaussian_gradient_magnitude, laplace\n",
    "\n",
    "from minerva.data.datasets.supervised_dataset import SupervisedReconstructionDataset\n",
    "from minerva.data.readers.png_reader import PNGReader\n",
    "from minerva.data.readers.tiff_reader import TiffReader\n",
    "from minerva.models.nets.image.segment_anything.sam_lora import SAMLoRA\n",
    "from minerva.transforms.transform import _Transform\n",
    "from minerva.pipelines.lightning_pipeline import SimpleLightningPipeline\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA Device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f3\n",
    "train_path = \"/workspaces/Minerva-Discovery/shared_data/seismic/f3_segmentation/images\"\n",
    "annotation_path = \"/workspaces/Minerva-Discovery/shared_data/seismic/f3_segmentation/annotations\"\n",
    "\n",
    "# seam-ai (parihaka)\n",
    "# train_path = \"/workspaces/Minerva-Discovery/shared_data/seam_ai_datasets/seam_ai/images\"\n",
    "# annotation_path = \"/workspaces/Minerva-Discovery/shared_data/seam_ai_datasets/seam_ai/annotations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchingTolstayaModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_path: str,\n",
    "        annotations_path: str,\n",
    "        patch_size: int = 255,\n",
    "        stride: int = 32,\n",
    "        batch_size: int = 8,\n",
    "        transforms: _Transform = None,\n",
    "        num_workers: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_path = Path(train_path)\n",
    "        self.annotations_path = Path(annotations_path)\n",
    "        self.transforms = transforms\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.num_workers = num_workers if num_workers else os.cpu_count()\n",
    "\n",
    "        self.datasets = {}\n",
    "\n",
    "    # função útil\n",
    "    def normalize_data(self, data):\n",
    "        \"\"\"\n",
    "        Normaliza os valores dos pixels para o intervalo [0, 1].\n",
    "        \"\"\"\n",
    "        data_min, data_max = data.min(), data.max()\n",
    "        return (data - data_min) / (data_max - data_min)\n",
    "\n",
    "    # função útil\n",
    "    def generate_depth_channel(self, shape):\n",
    "        \"\"\"\n",
    "        Função responsável por criar o canal de profundidade, com 0 no topo e 1 na base.\n",
    "        \"\"\"\n",
    "        depth_channel = np.linspace(0, 1, shape[0]).reshape(-1, 1)\n",
    "        return np.tile(depth_channel, (1, shape[1]))\n",
    "    \n",
    "    # função útil\n",
    "    def extract_patches(self, data, patch_size=255, stride=32, img_type='image'):\n",
    "        patches = []\n",
    "        if img_type == 'image': # caso seja imagens de entrada (h, w, c)\n",
    "            h, w, _ = data.shape\n",
    "        else: # caso seja labels de entrada (h, w)\n",
    "            h, w = data.shape\n",
    "        for i in range(0, h - patch_size + 1, stride):\n",
    "            for j in range(0, w - patch_size + 1, stride):\n",
    "                patch = data[i:i + patch_size, j:j + patch_size]\n",
    "                if img_type == 'image':\n",
    "                    patches.append(patch.transpose(2, 0, 1).astype(np.float32)) # o SAM só recebe (C H W)\n",
    "                else:\n",
    "                    patches.append(patch) #.astype(np.int64)\n",
    "        return np.array(patches)\n",
    "    \n",
    "    # funcao utils\n",
    "    def generate_facies_probability_channel(self, patch, facies_probabilities):\n",
    "        prob_map = np.random.choice(\n",
    "            len(facies_probabilities), size=patch.shape, p=facies_probabilities\n",
    "            )\n",
    "        return prob_map\n",
    "\n",
    "    # funcao util\n",
    "    def generate_amplitude_gradient_channel(self, patch):\n",
    "        # Usa gradiente de amplitude com suavização\n",
    "        gradient_channel = gaussian_gradient_magnitude(patch, sigma=1)\n",
    "        return gradient_channel / np.max(gradient_channel)  # Normalização\n",
    "\n",
    "    # funcao util\n",
    "    def generate_curvature_channel(self, patch):\n",
    "        # Calcula a curvatura usando o filtro de Laplace\n",
    "        curvature_channel = laplace(patch)\n",
    "        return curvature_channel / np.max(np.abs(curvature_channel))  # Normaliza para [-1, 1]\n",
    "\n",
    "    # função útil\n",
    "    def generate_image_with_depth(self, normalized_images):\n",
    "        two_channel_images = []\n",
    "        for img in normalized_images:  # Garantir que está trabalhando com imagens normalizadas\n",
    "            depth_channel = self.generate_depth_channel(img.shape[:2])  # Gerar canal de profundidade para esta imagem\n",
    "\n",
    "            if img.shape[-1] > 1:  # Se a imagem tiver múltiplos canais\n",
    "                # Escolher apenas o primeiro canal (exemplo, pode ser qualquer canal)\n",
    "                img = img[:, :, 0:1]  # Seleciona o primeiro canal e mantém as dimensões (H, W, 1)\n",
    "            \n",
    "            # gerando canal 3 (teste)\n",
    "            # facies_probabilities = np.array([0.2857, 0.1207, 0.4696, 0.0747, 0.0361, 0.0132])\n",
    "            # canal_3 = self.generate_facies_probability_channel(img, facies_probabilities)\n",
    "            # canal_3 = self.generate_amplitude_gradient_channel(img)\n",
    "            # canal_3 = self.generate_curvature_channel(img)\n",
    "\n",
    "            # Concatenar o primeiro canal com o depth_channel\n",
    "            depth_channel = np.expand_dims(depth_channel, axis=-1)  # Tornar (H, W, 1)\n",
    "            two_channel_image = np.concatenate((img, depth_channel), axis=-1)  # Concatenar ao longo do eixo dos canais\n",
    "            two_channel_images.append(two_channel_image)  # Adicionar ao array final\n",
    "        return two_channel_images\n",
    "    \n",
    "    # função util\n",
    "    def horizontal_flip(self, image, label):\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            raise ValueError(f\"Experado image com type <class 'numpy.ndarray'>, mas foi recebido {type(image)}\")\n",
    "        if not isinstance(label, np.ndarray):\n",
    "            raise ValueError(f\"Experado label com type <class 'numpy.ndarray'>, mas foi recebido {type(label)}\")\n",
    "\n",
    "        if image.shape[0] != 3 or image.shape[1] != self.patch_size or image.shape[2] != self.patch_size:\n",
    "            raise ValueError(f\"Experado image com shape (C=3 H=patch_size W=patch_size), mas foi recebido {image.shape}\")\n",
    "        if label.shape[0] != self.patch_size or label.shape[1] != self.patch_size:\n",
    "            raise ValueError(f\"Experado label com shape (H=patch_size W=patch_size), mas foi recebido {label.shape}\")\n",
    "\n",
    "        image_flipped = np.flip(image, axis=2)\n",
    "        label_flipped = np.flip(label, axis=1)\n",
    "\n",
    "        # if any(s < 0 for s in image_flipped.strides):\n",
    "        #     print(f\"array com strides negativos detectado\")\n",
    "\n",
    "        return image_flipped.copy(), label_flipped.copy()\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\":\n",
    "            train_img_reader = [self.normalize_data(image) for image in TiffReader(self.train_path / \"train\")] # lendo imagens e normalizando\n",
    "            train_label_reader = PNGReader(self.annotations_path / \"train\")\n",
    "            \n",
    "            # Gerar imagens com canais de profundidade\n",
    "            # train_img_reader = self.generate_image_with_depth(train_img_reader)\n",
    "            \n",
    "            # Gerar patches em batches\n",
    "            patches_img_generator = []\n",
    "            for image in train_img_reader:\n",
    "                patches_img_generator.extend(self.extract_patches(image, self.patch_size, self.stride))\n",
    "            patches_label_generator = []\n",
    "            for image in train_label_reader:\n",
    "                patches_label_generator.extend(self.extract_patches(image, self.patch_size, self.stride, img_type='label'))\n",
    "\n",
    "            # \"\"\" augmentation \"\"\"\n",
    "            # # Aplicar augmentações nas imagens e labels, somente para as amostras com 3, 4 ou 6 classes\n",
    "            # augmented_img_generator = []\n",
    "            # augmented_label_generator = []\n",
    "            # for img, label in zip(patches_img_generator, patches_label_generator):\n",
    "            #     # TODO tá estourando nessa parte\n",
    "            #     augmented_img_generator.append(img)\n",
    "            #     augmented_label_generator.append(label)\n",
    "            #     # Verificar o número de classes na amostra\n",
    "            #     unique_classes = np.unique(label)\n",
    "            #     num_classes = len(unique_classes)\n",
    "                \n",
    "            #     if num_classes in [3, 4, 6]:  # Apenas aplicar augmentação nas amostras com 3, 4 ou 6 classes\n",
    "            #         img_horizontal_flip, label_horizontal_flip = self.horizontal_flip(img, label)\n",
    "            #         augmented_img_generator.append(img_horizontal_flip)\n",
    "            #         augmented_label_generator.append(label_horizontal_flip)\n",
    "            \n",
    "            # Criar dataset para treinamento\n",
    "            self.datasets[\"train\"] = SupervisedReconstructionDataset(\n",
    "                readers=[patches_img_generator, patches_label_generator],\n",
    "                transforms=self.transforms,\n",
    "            )\n",
    "            del train_img_reader, train_label_reader\n",
    "            del patches_img_generator, patches_label_generator\n",
    "            # del augmented_img_generator, augmented_label_generator\n",
    "            gc.collect()\n",
    "\n",
    "            val_img_reader = [self.normalize_data(image) for image in TiffReader(self.train_path / \"val\")]\n",
    "            val_label_reader = PNGReader(self.annotations_path / \"val\")\n",
    "\n",
    "            # gerar imagens com canais de profundidade\n",
    "            # val_img_reader = self.generate_image_with_depth(val_img_reader)\n",
    "\n",
    "            # Gerar patches em batches\n",
    "            patches_img_generator = []\n",
    "            for image in val_img_reader:\n",
    "                patches_img_generator.extend(self.extract_patches(image, self.patch_size, self.stride))\n",
    "            patches_label_generator = []\n",
    "            for image in val_label_reader:\n",
    "                patches_label_generator.extend(self.extract_patches(image, self.patch_size, self.stride, img_type='label'))\n",
    "\n",
    "            self.datasets[\"val\"] = SupervisedReconstructionDataset(\n",
    "                readers=[patches_img_generator, patches_label_generator],\n",
    "                transforms=self.transforms,\n",
    "            )\n",
    "            del val_img_reader, val_label_reader\n",
    "            del patches_img_generator, patches_label_generator\n",
    "            gc.collect()\n",
    "        \n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            test_img_reader = [self.normalize_data(image) for image in TiffReader(self.train_path / \"test\")]\n",
    "            test_label_reader = PNGReader(self.annotations_path / \"test\")\n",
    "\n",
    "            # gerar imagens com canais de profundidade\n",
    "            # test_img_reader = self.generate_image_with_depth(test_img_reader)\n",
    "\n",
    "            # Gerar patches em batches\n",
    "            patches_img_generator = []\n",
    "            for image in test_img_reader:\n",
    "                patches_img_generator.extend(self.extract_patches(image, self.patch_size, self.stride))\n",
    "            patches_label_generator = []\n",
    "            for image in test_label_reader:\n",
    "                patches_label_generator.extend(self.extract_patches(image, self.patch_size, self.stride, img_type='label'))\n",
    "\n",
    "            test_dataset = SupervisedReconstructionDataset(\n",
    "                readers=[patches_img_generator, patches_label_generator],\n",
    "                transforms=self.transforms,\n",
    "            )\n",
    "            del test_img_reader, test_label_reader\n",
    "            del patches_img_generator, patches_label_generator\n",
    "            gc.collect()\n",
    "\n",
    "            self.datasets[\"test\"] = test_dataset\n",
    "            self.datasets[\"predict\"] = test_dataset\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid stage: {stage}\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets[\"train\"],\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=True, \n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets[\"val\"],\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True, \n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets[\"test\"],\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True, \n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets[\"predict\"],\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True, \n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def worker_init_fn(self, worker_id):\n",
    "        random.seed(18 + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

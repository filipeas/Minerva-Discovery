{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:53: UserWarning: Reliance on distutils from stdlib is deprecated. Users must rely on setuptools to provide the distutils module. Avoid importing distutils or import setuptools first, and avoid setting SETUPTOOLS_USE_DISTUTILS=stdlib. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu124\n",
      "CUDA Version: 12.4\n",
      "CUDA Available: True\n",
      "CUDA Device Count: 1\n",
      "CUDA Device Name: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "\n",
    "from scipy.ndimage import gaussian_gradient_magnitude, laplace\n",
    "\n",
    "from minerva.data.datasets.supervised_dataset import SupervisedReconstructionDataset\n",
    "from minerva.data.readers.png_reader import PNGReader\n",
    "from minerva.data.readers.tiff_reader import TiffReader\n",
    "from minerva.models.nets.image.segment_anything.sam_lora import SAMLoRA\n",
    "from minerva.transforms.transform import _Transform\n",
    "from minerva.pipelines.lightning_pipeline import SimpleLightningPipeline\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())\n",
    "print(\"CUDA Device Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No CUDA Device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f3\n",
    "train_path = \"/workspaces/Minerva-Discovery/shared_data/seismic/f3_segmentation/images\"\n",
    "annotation_path = \"/workspaces/Minerva-Discovery/shared_data/seismic/f3_segmentation/annotations\"\n",
    "\n",
    "# seam-ai (parihaka)\n",
    "# train_path = \"/workspaces/Minerva-Discovery/shared_data/seam_ai_datasets/seam_ai/images\"\n",
    "# annotation_path = \"/workspaces/Minerva-Discovery/shared_data/seam_ai_datasets/seam_ai/annotations\"\n",
    "\n",
    "checkpoint_path = \"/workspaces/Minerva-Discovery/shared_data/weights_sam/checkpoints_sam/sam_vit_b_01ec64.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchingTolstayaModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_path: str,\n",
    "        annotations_path: str,\n",
    "        patch_size: int = 255,\n",
    "        stride: int = 32,\n",
    "        batch_size: int = 8,\n",
    "        transforms: _Transform = None,\n",
    "        num_workers: int = None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_path = Path(train_path)\n",
    "        self.annotations_path = Path(annotations_path)\n",
    "        self.transforms = transforms\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.num_workers = num_workers if num_workers else os.cpu_count()\n",
    "\n",
    "        self.datasets = {}\n",
    "\n",
    "    # função útil\n",
    "    def normalize_data(self, data, target_min=-1, target_max=1):\n",
    "        \"\"\"\n",
    "        Função responsável por normalizar as imagens no intervalo (-1,1)\n",
    "        \"\"\"\n",
    "        data_min, data_max = data.min(), data.max()\n",
    "        return target_min + (data - data_min) * (target_max - target_min) / (data_max - data_min)\n",
    "\n",
    "    # função útil\n",
    "    def generate_depth_channel(self, shape):\n",
    "        \"\"\"\n",
    "        Função responsável por criar o canal de profundidade, com 0 no topo e 1 na base.\n",
    "        \"\"\"\n",
    "        depth_channel = np.linspace(0, 1, shape[0]).reshape(-1, 1)\n",
    "        return np.tile(depth_channel, (1, shape[1]))\n",
    "    \n",
    "    # função útil\n",
    "    def extract_patches(self, data, patch_size=255, stride=32, img_type='image'):\n",
    "        patches = []\n",
    "        if img_type == 'image': # caso seja imagens de entrada (h, w, c)\n",
    "            h, w, _ = data.shape\n",
    "        else: # caso seja labels de entrada (h, w)\n",
    "            h, w = data.shape\n",
    "        for i in range(0, h - patch_size + 1, stride):\n",
    "            for j in range(0, w - patch_size + 1, stride):\n",
    "                patch = data[i:i + patch_size, j:j + patch_size]\n",
    "                if img_type == 'image':\n",
    "                    patches.append(patch.astype(np.float32)) #transpose(2, 0, 1) o SAM só recebe (C H W)\n",
    "                else:\n",
    "                    patches.append(patch) #.astype(np.int64)\n",
    "        return np.array(patches)\n",
    "    \n",
    "    # funcao utils\n",
    "    def generate_facies_probability_channel(self, patch, facies_probabilities):\n",
    "        prob_map = np.random.choice(\n",
    "            len(facies_probabilities), size=patch.shape, p=facies_probabilities\n",
    "            )\n",
    "        return prob_map\n",
    "\n",
    "    # funcao util\n",
    "    def generate_amplitude_gradient_channel(self, patch):\n",
    "        # Usa gradiente de amplitude com suavização\n",
    "        gradient_channel = gaussian_gradient_magnitude(patch, sigma=1)\n",
    "        return gradient_channel / np.max(gradient_channel)  # Normalização\n",
    "\n",
    "    # funcao util\n",
    "    def generate_curvature_channel(self, patch):\n",
    "        # Calcula a curvatura usando o filtro de Laplace\n",
    "        curvature_channel = laplace(patch)\n",
    "        return curvature_channel / np.max(np.abs(curvature_channel))  # Normaliza para [-1, 1]\n",
    "\n",
    "    # função útil\n",
    "    def generate_image_with_depth(self, normalized_images):\n",
    "        two_channel_images = []\n",
    "        for img in normalized_images:  # Garantir que está trabalhando com imagens normalizadas\n",
    "            depth_channel = self.generate_depth_channel(img.shape[:2])  # Gerar canal de profundidade para esta imagem\n",
    "\n",
    "            if img.shape[-1] > 1:  # Se a imagem tiver múltiplos canais\n",
    "                # Escolher apenas o primeiro canal (exemplo, pode ser qualquer canal)\n",
    "                img = img[:, :, 0:1]  # Seleciona o primeiro canal e mantém as dimensões (H, W, 1)\n",
    "            \n",
    "            # gerando canal 3 (teste)\n",
    "            # facies_probabilities = np.array([0.2857, 0.1207, 0.4696, 0.0747, 0.0361, 0.0132])\n",
    "            # canal_3 = self.generate_facies_probability_channel(img, facies_probabilities)\n",
    "            # canal_3 = self.generate_amplitude_gradient_channel(img)\n",
    "            # canal_3 = self.generate_curvature_channel(img)\n",
    "\n",
    "            # Concatenar o primeiro canal com o depth_channel\n",
    "            depth_channel = np.expand_dims(depth_channel, axis=-1)  # Tornar (H, W, 1)\n",
    "            two_channel_image = np.concatenate((img, depth_channel), axis=-1)  # Concatenar ao longo do eixo dos canais\n",
    "            two_channel_images.append(two_channel_image)  # Adicionar ao array final\n",
    "        return two_channel_images\n",
    "    \n",
    "    # função util\n",
    "    def horizontal_flip(self, image, label):\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            raise ValueError(f\"Experado image com type <class 'numpy.ndarray'>, mas foi recebido {type(image)}\")\n",
    "        if not isinstance(label, np.ndarray):\n",
    "            raise ValueError(f\"Experado label com type <class 'numpy.ndarray'>, mas foi recebido {type(label)}\")\n",
    "\n",
    "        if image.shape[0] != 3 or image.shape[1] != self.patch_size or image.shape[2] != self.patch_size:\n",
    "            raise ValueError(f\"Experado image com shape (C=3 H=patch_size W=patch_size), mas foi recebido {image.shape}\")\n",
    "        if label.shape[0] != self.patch_size or label.shape[1] != self.patch_size:\n",
    "            raise ValueError(f\"Experado label com shape (H=patch_size W=patch_size), mas foi recebido {label.shape}\")\n",
    "\n",
    "        image_flipped = np.flip(image, axis=2)\n",
    "        label_flipped = np.flip(label, axis=1)\n",
    "\n",
    "        # if any(s < 0 for s in image_flipped.strides):\n",
    "        #     print(f\"array com strides negativos detectado\")\n",
    "\n",
    "        return image_flipped.copy(), label_flipped.copy()\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\":\n",
    "            train_img_reader = [self.normalize_data(image) for image in TiffReader(self.train_path / \"train\")] # lendo imagens e normalizando\n",
    "            train_label_reader = PNGReader(self.annotations_path / \"train\")\n",
    "            \n",
    "            # Gerar imagens com canais de profundidade\n",
    "            # train_img_reader = self.generate_image_with_depth(train_img_reader)\n",
    "            \n",
    "            # Gerar patches em batches\n",
    "            patches_img_generator = []\n",
    "            for image in train_img_reader:\n",
    "                patches_img_generator.extend(self.extract_patches(image, self.patch_size, self.stride))\n",
    "            patches_label_generator = []\n",
    "            for image in train_label_reader:\n",
    "                patches_label_generator.extend(self.extract_patches(image, self.patch_size, self.stride, img_type='label'))\n",
    "\n",
    "            # \"\"\" augmentation \"\"\"\n",
    "            # # Aplicar augmentações nas imagens e labels, somente para as amostras com 3, 4 ou 6 classes\n",
    "            # augmented_img_generator = []\n",
    "            # augmented_label_generator = []\n",
    "            # for img, label in zip(patches_img_generator, patches_label_generator):\n",
    "            #     # TODO tá estourando nessa parte\n",
    "            #     augmented_img_generator.append(img)\n",
    "            #     augmented_label_generator.append(label)\n",
    "            #     # Verificar o número de classes na amostra\n",
    "            #     unique_classes = np.unique(label)\n",
    "            #     num_classes = len(unique_classes)\n",
    "                \n",
    "            #     if num_classes in [3, 4, 6]:  # Apenas aplicar augmentação nas amostras com 3, 4 ou 6 classes\n",
    "            #         img_horizontal_flip, label_horizontal_flip = self.horizontal_flip(img, label)\n",
    "            #         augmented_img_generator.append(img_horizontal_flip)\n",
    "            #         augmented_label_generator.append(label_horizontal_flip)\n",
    "            \n",
    "            # Criar dataset para treinamento\n",
    "            self.datasets[\"train\"] = SupervisedReconstructionDataset(\n",
    "                readers=[patches_img_generator, patches_label_generator],\n",
    "                transforms=self.transforms,\n",
    "            )\n",
    "            del train_img_reader, train_label_reader\n",
    "            del patches_img_generator, patches_label_generator\n",
    "            # del augmented_img_generator, augmented_label_generator\n",
    "            gc.collect()\n",
    "\n",
    "            val_img_reader = [self.normalize_data(image) for image in TiffReader(self.train_path / \"val\")]\n",
    "            val_label_reader = PNGReader(self.annotations_path / \"val\")\n",
    "\n",
    "            # gerar imagens com canais de profundidade\n",
    "            # val_img_reader = self.generate_image_with_depth(val_img_reader)\n",
    "\n",
    "            # Gerar patches em batches\n",
    "            patches_img_generator = []\n",
    "            for image in val_img_reader:\n",
    "                patches_img_generator.extend(self.extract_patches(image, self.patch_size, self.stride))\n",
    "            patches_label_generator = []\n",
    "            for image in val_label_reader:\n",
    "                patches_label_generator.extend(self.extract_patches(image, self.patch_size, self.stride, img_type='label'))\n",
    "\n",
    "            self.datasets[\"val\"] = SupervisedReconstructionDataset(\n",
    "                readers=[patches_img_generator, patches_label_generator],\n",
    "                transforms=self.transforms,\n",
    "            )\n",
    "            del val_img_reader, val_label_reader\n",
    "            del patches_img_generator, patches_label_generator\n",
    "            gc.collect()\n",
    "        \n",
    "        elif stage == \"test\" or stage == \"predict\":\n",
    "            test_img_reader = [self.normalize_data(image) for image in TiffReader(self.train_path / \"test\")]\n",
    "            test_label_reader = PNGReader(self.annotations_path / \"test\")\n",
    "\n",
    "            # gerar imagens com canais de profundidade\n",
    "            # test_img_reader = self.generate_image_with_depth(test_img_reader)\n",
    "\n",
    "            # Gerar patches em batches\n",
    "            patches_img_generator = []\n",
    "            for image in test_img_reader:\n",
    "                patches_img_generator.extend(self.extract_patches(image, self.patch_size, self.stride))\n",
    "            patches_label_generator = []\n",
    "            for image in test_label_reader:\n",
    "                patches_label_generator.extend(self.extract_patches(image, self.patch_size, self.stride, img_type='label'))\n",
    "\n",
    "            test_dataset = SupervisedReconstructionDataset(\n",
    "                readers=[patches_img_generator, patches_label_generator],\n",
    "                transforms=self.transforms,\n",
    "            )\n",
    "            del test_img_reader, test_label_reader\n",
    "            del patches_img_generator, patches_label_generator\n",
    "            gc.collect()\n",
    "\n",
    "            self.datasets[\"test\"] = test_dataset\n",
    "            self.datasets[\"predict\"] = test_dataset\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid stage: {stage}\")\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets[\"train\"],\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=True, \n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets[\"val\"],\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True, \n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets[\"test\"],\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True, \n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.datasets[\"predict\"],\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            pin_memory=True, \n",
    "            drop_last=False\n",
    "        )\n",
    "\n",
    "    def worker_init_fn(self, worker_id):\n",
    "        random.seed(18 + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((64, 64)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "data_module = PatchingTolstayaModule(\n",
    "    train_path=train_path,\n",
    "    annotations_path=annotation_path,\n",
    "    patch_size=255,\n",
    "    stride=32,\n",
    "    batch_size=8,\n",
    "    transforms=[transform, transform]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_module.setup(stage='fit')\n",
    "# train_loader = data_module.train_dataloader()\n",
    "# for batch in train_loader:\n",
    "#     x, label = batch\n",
    "#     print(x.shape, label.shape)  # Imprime o shape do tensor\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minerva.models.nets.image.convae import ConvVAE\n",
    "model = ConvVAE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log directory set to: /workspaces/Minerva-Discovery/my_experiments/vae_v1/notebook/logs/sam_model/version_39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /workspaces/Minerva-Discovery/my_experiments/vae_v1/notebook/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name           | Type       | Params | Mode \n",
      "------------------------------------------------------\n",
      "0 | encoder_conv   | Sequential | 93.2 K | train\n",
      "1 | mu             | Sequential | 32.8 K | train\n",
      "2 | log_var        | Sequential | 32.8 K | train\n",
      "3 | decoder_linear | Sequential | 33.8 K | train\n",
      "4 | decoder_conv   | Sequential | 93.2 K | train\n",
      "------------------------------------------------------\n",
      "285 K     Trainable params\n",
      "0         Non-trainable params\n",
      "285 K     Total params\n",
      "1.143     Total estimated model params size (MB)\n",
      "31        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 1026/1026 [00:06<00:00, 157.17it/s, v_num=39, val_loss=0.542, val_recon_loss=0.0416, val_kl_loss=0.500, train_loss=0.542, train_recon_loss=0.0417, train_kl_loss=0.500]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/event_file_writer.py\", line 233, in run\n",
      "    self._record_writer.write(data)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/summary/writer/record_writer.py\", line 40, in write\n",
      "    self._writer.write(header + header_crc + data + footer_crc)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 766, in write\n",
      "    self.fs.append(self.filename, file_content, self.binary_mode)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 160, in append\n",
      "    self._write(filename, file_content, \"ab\" if binary_mode else \"a\")\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/tensorboard/compat/tensorflow_stub/io/gfile.py\", line 164, in _write\n",
      "    with io.open(filename, mode, encoding=encoding) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: b'logs/sam_model/version_39/events.out.tfevents.1732216596.6e04ea739046.1637.0'\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    }
   ],
   "source": [
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# Define o callback para salvar o modelo com base no menor valor da métrica de validação\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\", # Métrica para monitorar\n",
    "    dirpath=\"./checkpoints\", # Diretório onde os checkpoints serão salvos\n",
    "    filename=f\"tolstaya-sam_model-{current_date}-{{epoch:02d}}-{{val_loss:.2f}}\", # Nome do arquivo do checkpoint\n",
    "    save_top_k=1, # Quantos melhores checkpoints salvar (no caso, o melhor)\n",
    "    mode=\"min\", # Como a métrica deve ser tratada (no caso, 'min' significa que menor valor de val_loss é melhor)\n",
    ")\n",
    "\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "# Defina o logger do TensorBoard\n",
    "logger = TensorBoardLogger(\"logs\", name=\"sam_model\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=50,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    logger=logger,\n",
    "    callbacks=[checkpoint_callback],\n",
    ")\n",
    "# trainer.fit(model, data_module)\n",
    "\n",
    "pipeline = SimpleLightningPipeline(\n",
    "    model=model,\n",
    "    trainer=trainer,\n",
    "    save_run_status=True\n",
    ")\n",
    "\n",
    "pipeline.run(data=data_module, task=\"fit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
